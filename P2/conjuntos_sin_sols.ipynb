{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Máster Universitario en Ciencia de Datos\n",
    "### Métodos Avanzados en Aprendizaje Automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuntos de clasificadores\n",
    "Este notebook muestrael funcionamiento básico de los conjuntos de clasificadores. Se muestras algunos ejemplos en problemas en 2D para su visualización y con problemas reales para ver sus capacidades y debilidades. Los temas que se tratan son:\n",
    "\n",
    "\n",
    "* Proceso de combinación de clasificadores base en conjuntos y cómo se modifican las fronteras de decisión \n",
    "* Tiempos de entrenamiento y de clasificación en  conjuntos de clasificadores y ver cómo varía con respecto a la creación de un único árbol\n",
    "* Errores de generalización de conjuntos de clasificadores en conjuntos de datos reales\n",
    "* Importancia de las variables de entrenamiento en el modelo.\n",
    "\n",
    "Todas las cuestiones se contestarán en este notebook directamente, que es lo que deberéis entregar.\n",
    "Las cuestiones a responder están marcadas con fondo verde y vuestras respuestas deben ir en los cuadros en amarillo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones auxiliares\n",
    "Se definen conjuntos de datos en 2D para el análisis visual de las fronteras de decisión y cómo cambian con algunos parámetros. Se definin algunas funciones (inspiradas en sklearn) que usaremos a lo largo de la práctica. \n",
    "\n",
    "La primera, *createDataSet*, es para crear los problemas, siempre con dos clases y en dos dimensiones. Sus argumentos son:\n",
    "\n",
    "- *n*, número de patrones en el problema\n",
    "\n",
    "- *model*, tipo de modelo para la frontera que separa las clases, puede ser 'linear', 'square' o 'sine'\n",
    "\n",
    "- *ymargin*, margen de separación entre las dos clases, cuanto mayor es *ymargin* más separadas están las clases, valores negativos implican solape entre las clases\n",
    "\n",
    "- *noise*, introduce un ruido gausiano a la x e y\n",
    "\n",
    "- *output_boundary*, Si vale True la función devuelve la frontera de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet(n,model,ymargin,noise=None,output_boundary=False):\n",
    "    x = np.random.rand(n,1)*2.0*np.pi\n",
    "    xbnd = np.linspace(0,2.0*np.pi,100)\n",
    "\n",
    "    if model == 'sine':\n",
    "        y = (np.random.rand(n,1) - 0.5)*2.2\n",
    "        c = y > np.sin(x)\n",
    "        ybnd = np.sin(xbnd)\n",
    "    elif model == 'linear':\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    elif model == 'square':\n",
    "        y = np.random.rand(n,1)*4.0*np.pi*np.pi\n",
    "        c = y > x*x\n",
    "        ybnd = xbnd*xbnd\n",
    "    else:\n",
    "        y = np.random.rand(n,1)*2.0*np.pi\n",
    "        c = y > x\n",
    "        ybnd = xbnd\n",
    "    \n",
    "    y[c == True] = y[c == True] + ymargin\n",
    "    y[c == False] = y[c == False] - ymargin\n",
    "    \n",
    "    if noise is not None:\n",
    "        y = y + noise * np.random.randn(n,1)\n",
    "        x = x + noise * np.random.randn(n,1)\n",
    "\n",
    "    if output_boundary == True:\n",
    "        return x, y, (c*1).ravel(), xbnd, ybnd\n",
    "    else:\n",
    "        return x, y, (c*1).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función *plotModel* la usaremos para dibujar el resultado de un clasificador sobre el conjunto de datos. Sus argumentos son:\n",
    "\n",
    "- *x*, coordenada x de los puntos\n",
    "\n",
    "- *y*, coordenada y de los puntos\n",
    "\n",
    "- *c*, clase de los puntos, si se pasa None, entonces considera que x e y son la frontera real de decisión y la muestra con plot\n",
    "\n",
    "- *clf*, el clasificador\n",
    "\n",
    "- *title*, título para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotModel(x,y,clase,clf,title=\"\"):\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    \n",
    "    x_min, x_max = x.min() - .2, x.max() + .2\n",
    "    y_min, y_max = y.min() - .2, y.max() + .2\n",
    "    hx = (x_max - x_min)/100.\n",
    "    hy = (y_max - y_min)/100.\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, hx), np.arange(y_min, y_max, hy))\n",
    "\n",
    "    if hasattr(clf, \"decision_function\"):\n",
    "        z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    elif hasattr(clf, \"predict_proba\"):\n",
    "        z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    else:\n",
    "        z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    z = z.reshape(xx.shape)\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    \n",
    "    plt.contourf(xx, yy, z, cmap=cm, alpha=.8)\n",
    "    plt.contour(xx, yy, z, [0.5], linewidths=[2], colors=['k'])\n",
    "\n",
    "    if clase is not None:\n",
    "        plt.scatter(x[clase==0], y[clase==0], c='#FF0000')\n",
    "        plt.scatter(x[clase==1], y[clase==1], c='#0000FF')\n",
    "    else:\n",
    "        plt.plot(x,y,'g', linewidth=3)\n",
    "        \n",
    "    plt.gca().set_xlim(xx.min(), xx.max())\n",
    "    plt.gca().set_ylim(yy.min(), yy.max())\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función, *plotData*, la usaremos para dibujar los datos. Sus argumentos son:\n",
    "\n",
    "- *x*, coordenada x de los puntos\n",
    "\n",
    "- *y*, coordenada y de los puntos\n",
    "\n",
    "- *c*, clase de los puntos\n",
    "\n",
    "- *style0*, estilo con el que pintamos los puntos de la clase 0\n",
    "\n",
    "- *style1*, estilo con el que pintamos los puntos de la clase 1\n",
    "\n",
    "- *title*, título para el gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(x,y,c,style0,style1,title=''):\n",
    "    plt.scatter(x[c==0],y[c==0],**style0)\n",
    "    plt.scatter(x[c==1],y[c==1],**style1)\n",
    "    plt.grid(True)\n",
    "    plt.axis([x.min()-0.2, x.max()+0.2, y.min()-0.2, y.max()+0.2])\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem data:\n",
    "np.random.seed(11)\n",
    "n = 300\n",
    "model = 'sine'\n",
    "ymargin = 0.\n",
    "noise = 0.0             # <========= Modifica este valor 0 ó 0.3, (antes responde a las cuestiones de arriba)\n",
    "x1, x2, ytrain, xbnd, ybnd = createDataSet(n, model, ymargin, noise, True)\n",
    "x1test, x2test, ytest = createDataSet(n*10, model, ymargin, noise)\n",
    "plotData(x1,x2,ytrain,{'c':'#FF0000'},{'c':'#0000FF'})\n",
    "Xtrain = np.concatenate((x1, x2), axis = 1)\n",
    "Xtest = np.concatenate((x1test, x2test), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teorema de Condorcet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_error = 0.6  # <-- Modifica esta probabilidad para ver cómo evoluciona \n",
    "                  #     la probabilidad de equivocarse del jurado\n",
    "num_jueces = 31   # Mejor que sea impar para evitar empates\n",
    "\n",
    "p_error_jurado = np.zeros(num_jueces)\n",
    "for i in range(1,num_jueces+1,2):\n",
    "    mayoria = 1 + i//2\n",
    "    p_error_jurado[i-1] = np.sum(sp.stats.binom.pmf(range(mayoria,i+1), i, prob_error))\n",
    "\n",
    "# Puedes cambiar a semilogy para ver mejor cómo baja la prob de error\n",
    "plt.plot(range(1,num_jueces+1,2),p_error_jurado[::2])\n",
    "plt.ylabel('Prob. de error del jurado')\n",
    "_ = plt.xlabel('Número de jueces')\n",
    "\n",
    "# Algunas cuestiones:\n",
    "#   * ¿Cuántos jueces necesitas para estar tener una prob del 99%\n",
    "#      de que el jurado acierte con prob_error=0.3? ¿y con prob_error=0.1? \n",
    "#      ¿y con 0.45?\n",
    "#   * ¿Qué sucede si la probabilidad de equivocarse de cada juez es >0.5?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestras bootstrap y bagging\n",
    "Una muestra bootstrap estándar consiste realizar N extracciones aleatorias con reemplazamiento de una urna con N elementos. Algunas variaciones incluyen:\n",
    "\n",
    "* Realizar M extracciones con $M\\neq N$\n",
    "* Realizar las extracciones sin reemplazamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array(range(1,1201,1))\n",
    "M2 = np.array(range(1,1001,1))\n",
    "N = 1000\n",
    "\n",
    "plt.plot(M, ((N-1)/N)**M, label='M de {} con reemp.'.format(N))\n",
    "plt.plot(M2, (N-M2)/N, label='M de {} sin reemp.'.format(N))\n",
    "plt.plot([0,N],[((N-1)/N)**N,((N-1)/N)**N],'k--')\n",
    "plt.plot([N,N],[0,((N-1)/N)**N],'k--')\n",
    "plt.xlim([0,M[-1]])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('Fracción de instancias no seleccionadas')\n",
    "plt.xlabel('Número de extracciones con repetición (M)')\n",
    "_=plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class BaggingCasero:\n",
    "    def __init__(self, n_estimators=101):\n",
    "        self.n_estimators = n_estimators\n",
    "        self._estimators = []\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        N = X.shape[0]\n",
    "        for i in range(self.n_estimators):\n",
    "            \"\"\"\n",
    "              Rellenar esta parte para que cree un árbol usando\n",
    "              una muestra bootstrap de los datos\n",
    "            \"\"\"\n",
    "            self._estimators.append(tree)\n",
    "            \n",
    "    def predict(self,X):\n",
    "        votos = np.zeros((X.shape[0],len(self._estimators)))\n",
    "        # Calcula la salida de cada árbol para cada dato\n",
    "        for ie,estimator in enumerate(self._estimators):\n",
    "            votos[:,ie] = estimator.predict(X)\n",
    "            \n",
    "        \"\"\"\n",
    "           Calcula la clase más votada de cada ejemplo, es decir,\n",
    "           la moda\n",
    "        \"\"\"\n",
    "        return moda\n",
    "            \n",
    "        \n",
    "            \n",
    "bagging = BaggingCasero()\n",
    "\n",
    "bagging.fit(Xtrain, ytrain)\n",
    "\n",
    "plotModel(x1,x2,ytrain,bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\"\"\" Solo se va a implementar para regresión y para clasificación \n",
    "    binaria con clases igual a -1 y +1\n",
    "\"\"\"\n",
    "\n",
    "class SquaredErrorLoss:\n",
    "    \"\"\" Clase que define elementos para la función cuadrática de perdida \n",
    "        para regresión \"\"\"\n",
    "    \n",
    "    def F0(_, X, y):\n",
    "        \"\"\" Calcula el valor constate que minimiza la salida 'y' \"\"\"\n",
    "        pass\n",
    "\n",
    "    def residuos(_, y, F):\n",
    "        \"\"\" Calcula los residuos para un objetivo 'y' y \n",
    "            una salida del modelo F \"\"\"\n",
    "        pass\n",
    "\n",
    "    ## CAMBIO 01\n",
    "    def paso_newton_hoja(_, y, residuos, valor):\n",
    "        \"\"\" Función para actualizar la salida de una hoja el árbol\n",
    "        \n",
    "           Recibe información sobre los ejemplos de una hoja dada. En concreto\n",
    "           para los ejemplos que caen en una hoja:\n",
    "              * El vector de valores a predecir (y)\n",
    "              * Los pseudo-residuos (residuos) sobre los que se ha\n",
    "                entrenado alarbol regresor ht\n",
    "           Además recine el valor actual de salida de la hoja\n",
    "              \n",
    "            Debe devolver el valor actualizado\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, y, F):\n",
    "        \"\"\" Devuelve el valor de la función de pérdida para un objetivo 'y' y \n",
    "            una salida del modelo F \"\"\"\n",
    "        return 0.5*(y-F)**2\n",
    "    \n",
    "class LogLoss:\n",
    "    \"\"\" Clase que define elementos para la función logística de perdida \n",
    "        para clasificación de dos clases {-1, +1} \"\"\"\n",
    "    \n",
    "    def F0(_, X, y):\n",
    "        \"\"\" Calcula el valor constate que minimiza la salida 'y' \"\"\"\n",
    "        pass\n",
    "\n",
    "    def residuos(_, y, F):\n",
    "        \"\"\" Calcula los residuos para un objetivo 'y' y \n",
    "            una salida del modelo F \"\"\"\n",
    "        pass\n",
    "\n",
    "    ## CAMBIO 02\n",
    "    def paso_newton_hoja(_, y, residuos, valor):\n",
    "        \"\"\" Función para actualizar la salida de una hoja el árbol\n",
    "        \n",
    "           Recibe información sobre los ejemplos de una hoja dada. En concreto\n",
    "           para los ejemplos que caen en una hoja:\n",
    "              * El vector de valores a predecir (y)\n",
    "              * Los pseudo-residuos (residuos) sobre los que se ha\n",
    "                entrenado alarbol regresor ht\n",
    "           Además recine el valor actual de salida de la hoja\n",
    "              \n",
    "            Debe devolver el valor actualizado\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __call__(self,y, F):\n",
    "        \"\"\" Devuelve el valor de la función de pérdida para un objetivo 'y' y \n",
    "            una salida del modelo F \"\"\"\n",
    "        return np.log(1+np.exp(-2.0*y*F))\n",
    "     \n",
    "class GBCasero:\n",
    "    def __init__(self, n_estimators=101, loss=SquaredErrorLoss(), eta=0.1, depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self._estimators  = []\n",
    "        self.depth        = depth\n",
    "        self.eta          = eta\n",
    "        # La implementación de loss se usará en fit para crear el algoritmo\n",
    "        # GB de forma genérica.\n",
    "        self.loss         = loss\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "          Inicializa GB \n",
    "        \"\"\"\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = DecisionTreeRegressor(max_depth = self.depth)\n",
    "            \"\"\"\n",
    "              Rellenar esta parte para implementar GB \n",
    "              Se debe utilizar la función paso_newton de abajo\n",
    "            \"\"\"\n",
    "            self._estimators.append(tree)\n",
    "            \n",
    "    def predict(self,X):\n",
    "        \"\"\" Combinamos los valores de pesos y hs para obtener la 'salida', y:\n",
    "               * Para regresión se devuelve 'salida'\n",
    "               * Para clasificación de 2 clases se calcula la probabilidad\n",
    "                  con una sigmoidal (1 / (1 + np.exp(-2*salida))) y se \n",
    "                  devuelve la clase más probable \"\"\"\n",
    "        return result\n",
    "            \n",
    "    ## CAMBIO 03\n",
    "    def paso_newton_general(self, tree, X, y, residuos):\n",
    "        \"\"\" Esta función actualiza todas las hojas de salida\n",
    "            del árbol 'tree' utilizado la función paso_newton_hoja\n",
    "            de las clases de funcion de pérdida \"\"\"\n",
    "        TREE_LEAF = -1\n",
    "        tree = tree.tree_\n",
    "        leaf_indices = tree.apply(np.array(X,dtype=np.float32))\n",
    "        for leaf in np.where(tree.children_left == TREE_LEAF)[0]:\n",
    "            ii = leaf_indices==leaf\n",
    "            tree.value[leaf,0,0] = self.loss.paso_newton_hoja(y[ii],\n",
    "                                                              residuos[ii],\n",
    "                                                              tree.value[leaf,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CAMBIO 04: Todas las pruebas\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Basic example\n",
    "gb = GBCasero(loss=LogLoss())\n",
    "\n",
    "lb     = LabelBinarizer(pos_label = 1, neg_label = -1)\n",
    "ytrain = lb.fit_transform(ytrain).ravel()\n",
    "ytest  = lb.transform(ytest).ravel()\n",
    "\n",
    "gb.fit(Xtrain, ytrain)\n",
    "acc = np.sum(gb.predict(Xtest)==ytest)/len(ytest)\n",
    "plotModel(x1,x2,ytrain,gb,\"Acc=\"+str(acc))\n",
    "\n",
    "# Magic\n",
    "fP = 'magic04.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(dfP.values[:,:-1], dfP.values[:,-1], \n",
    "                                          test_size=0.8, random_state=1)\n",
    "lb   = LabelBinarizer(pos_label = 1, neg_label = -1)\n",
    "y_tr = lb.fit_transform(y_tr).ravel()\n",
    "y_ts = lb.transform(y_ts).ravel()\n",
    "\n",
    "gb = GBCasero(loss=LogLoss())\n",
    "\n",
    "gb.fit(X_tr, y_tr)\n",
    "print(\"Accuracy in Magic04=\",np.sum(gb.predict(X_ts)==y_ts)/len(y_ts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar el conjunto\n",
    "Se entrena un random forest con 3 árboles para visualizar la frontera de decisión cuándo se combinan en el conjunto de clasificadores y cada árbol por separado\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Ejecuta el código de con noise=0 y n_estimators=3 y estudia el resultado de los árboles por separado y en conjunto. En concreto analiza:\n",
    "<ul>\n",
    "<li> (1) Las fronteras de decisión de los árboles individuales con respecto a la frontera de los árboles combinados.</li>\n",
    "<li> (2) ¿Por qué son tan diferentes las fronteras de los árboles individuales? Para responder piensa cómo se han creado esos árboles</li>\n",
    "<li> (3) Mira los errores en test de los árboles individuales y del conjunto ¿Cuál es que mejor error obtine? ¿Por qué?</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuestas:\n",
    "    <b>Nota: No es necesario entregar ninguna de estas cuestiones</b> \n",
    "<ul>\n",
    "<li> (1) ...</li>\n",
    "<li> (2) ...</li>\n",
    "<li> (3) ...</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Ahora ejecuta las dos celdas siguientes modificando el nivel de ruiso (noise=0.0 y noise=0.3). A continuación prueba con n_estimators igual a 3, 31 y 301 para cada uno de los niveles de ruido y rellena el acierto en test y train en la siguiente tabla:<br/></div>\n",
    "<br>\n",
    "\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">\n",
    "\n",
    "(4) Respuestas:\n",
    "\n",
    "| Acierto train/test | n_estimators=3 | n_estimators=31 | n_estimators=301 |\n",
    "|--------------------|----------------|-----------------|------------------|\n",
    "| noise=0            |                |                 |                  |\n",
    "| noise=0,3          |                |                 |                  | \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Construcción del clasificador:\n",
    "np.random.seed(11)\n",
    "clf = RandomForestClassifier(n_estimators=3) # <= Modif este valor 3, 31 y 301(antes responde a las cuestiones de arriba)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Calculo del acierto en los conjuntos de entrenamiento y test:\n",
    "score_train = clf.score(Xtrain, ytrain)\n",
    "print(\"Score train = %f\" % (score_train))\n",
    "score_test = clf.score(Xtest, ytest)\n",
    "print(\"Score test = %f\" % (score_test))\n",
    "\n",
    "scores_single_trees_test = [dt.score(Xtest, ytest) for dt in clf.estimators_[0:3]]\n",
    "\n",
    "print(\"Score test tres primeros árboles = %f,%f,%f\" % tuple(scores_single_trees_test))\n",
    "\n",
    "# Gráficas:\n",
    "plt.figure(figsize=(18,12))\n",
    "\n",
    "plt.subplot(231)\n",
    "t = \"Conjunto completo (acierto train = {:g})\".format(score_train)\n",
    "plotModel(x1,x2,ytrain,clf,t)\n",
    "\n",
    "plt.subplot(232)\n",
    "t = \"Conjunto completo (acierto test = {:g})\".format(score_test)\n",
    "plotModel(xbnd,ybnd,None,clf,t)\n",
    "\n",
    "# Se muestra el acierto y frontera de los 3 primeros árboles\n",
    "# del conjunto\n",
    "for i in [1,2,3]:\n",
    "    plt.subplot(2,3,3+i)\n",
    "    t = \"Arbol {}, acierto test = {:g}\".format(i,scores_single_trees_test[i-1])\n",
    "    plotModel(x1,x2,ytrain,clf.estimators_[i-1],t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">A continuación se realiza el cálculo el acierto del conjunto con en train y en test con respecto al número de clasificadores combinados. Puedes utilizar la función suministrada individualPredictions, que dado un conjunto de datos y otro de clasificadores devuelve las clasificaciones de cada clasificador base para cada ejemplo\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individualPredictions: Devuelve la predicción para cada dato por parte de cada clasificador \n",
    "#                        de un conjunto de clasificadores\n",
    "#     Entrada:\n",
    "#         - ens: lista con un conjunto de clasificadores\n",
    "#         - X  : ejemplos a clasificar\n",
    "#     Salida:\n",
    "#         - Matriz de predicciones de número de ejemplo filas y no. clasificadores columnas\n",
    "def individualPredictions(ens, X):\n",
    "    P = np.ones((X.shape[0],len(ens)))\n",
    "    it = 0\n",
    "    for dt in ens:\n",
    "        P[:,it] = dt.predict(X)\n",
    "        it += 1\n",
    "\n",
    "    return P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def accuracy(ens, pr, y):\n",
    "    pr = np.cumsum(pr,axis=1)/np.arange(1.,pr.shape[1]+1,1.)\n",
    "    pr[pr>0.5] = 1\n",
    "    pr[pr<=0.5] = 0\n",
    "\n",
    "    iclases_test = np.zeros(np.array([y]).T.shape)\n",
    "    iclases_test[y==ens.classes_[0]] = 0\n",
    "    iclases_test[y==ens.classes_[1]] = 1\n",
    "\n",
    "    Pok = pr==iclases_test\n",
    "    return np.array(Pok.sum(axis=0),dtype=float)/len(y)\n",
    "\n",
    "    \n",
    "# Cargamos datos\n",
    "fP = 'magic04.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "#separación training-test\n",
    "X_train, X_test, clases_train, clases_test = train_test_split(dfP.values[:,:-1], dfP.values[:,-1], test_size=0.8, random_state=1)\n",
    "\n",
    "n_trees = 500\n",
    "clf = RandomForestClassifier(n_estimators=n_trees)\n",
    "clf.fit(X_train, clases_train)\n",
    "\n",
    "P = individualPredictions(clf.estimators_, X_train)\n",
    "accu_tr = accuracy(clf,P,clases_train)\n",
    "\n",
    "P = individualPredictions(clf.estimators_, X_test)\n",
    "accu_ts = accuracy(clf,P,clases_test)\n",
    "\n",
    "plt.plot(range(1,n_trees+1),accu_tr,label=\"train\")\n",
    "plt.plot(range(1,n_trees+1),accu_ts,label=\"test\")\n",
    "plt.ylim([0.8,1])\n",
    "_ = plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Usando la tabla y la gráfica describe cómo evoluciona el error en en entrenemiento y test con respecto al número de árboles que se combinan en el conjunto ¿Se observa sobre ajuste al aumentar el número de clasificadores? Es decir, ¿sube el error en test a partir de algún umbral del número de clasificadores?<br/></div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">(5) Respuesta: \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting para regresión\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Tiempos de entrenamiento y test de los árboles de decisión\n",
    "Vamos a medir tiempos de entrenamiento y clasificación de árboles de decisión y a compararlos con los tiempos de las SVMs. Probaremos a entrenar los modelos con 300 datos y con 600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as skpp\n",
    "import timeit\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "n_executions = 1\n",
    "\n",
    "# Cargamos datos\n",
    "fP = 'pimaND.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "# Dividimos train/test\n",
    "n_train = 300                                      # <================== Modificar 300 o 600\n",
    "perm = np.random.permutation(dfP.shape[0])\n",
    "indices_train = perm[0:n_train]\n",
    "indices_test  = perm[n_train:]\n",
    "\n",
    "    \n",
    "#clf = SVC(C=10.0, kernel='linear', degree=1.0, coef0=1.0, gamma=0.1) # <================== Modificar DT o SVM\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "clf = RandomForestClassifier(n_estimators=100)  # <================== Modificar 100 o 1000\n",
    "\n",
    "# Tiempo de entrenamiento\n",
    "tic = timeit.default_timer()\n",
    "for ie in range(n_executions):    # Puede ser necesario ejecutarlo varias veces para obtener tiempos más estables\n",
    "    clf.fit(dfP.values[indices_train,:-1],dfP.values[indices_train,-1])\n",
    "toc = timeit.default_timer()\n",
    "\n",
    "print(\"Tiempo de entrenamiento con {} ejemplos: {:.4g} s.\".format(len(indices_train),(toc - tic)/n_executions))\n",
    "\n",
    "n_executions = 10\n",
    "\n",
    "# Tiempo de clasificacion\n",
    "tic = timeit.default_timer()\n",
    "for ie in range(n_executions):   # Puede ser necesario ejecutarlo varias veces para obtener tiempos más estables\n",
    "    _ = clf.predict(dfP.values[indices_test,:-1])\n",
    "toc = timeit.default_timer()\n",
    "\n",
    "factor = 100.\n",
    "print(\"Tiempo de clasificar {:g} ejemplos: {:.4g} s.\".format(factor, factor*(toc - tic)/n_executions/len(indices_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Se debe ejecutar la celda de arriba utilizando conjuntos de clasificadores con 100 y 1000 árboles. Hazlo usando 300 datos de entrenamiento y 600. A continuación se debe rellenar los tiempos en la siguiente tabla comparando con lo obtenido en con árboles y SVM:<br/></div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">(6) Respuestas:\n",
    "\n",
    "|  Tiempos (s)          | Árbol  | SVM  | RF100 | RF 1000 |\n",
    "|-----------------------|--------|------|-------|---------|\n",
    "| Entrenamiento con 300 | (+)    | (+)  | (++)  | (++)    |\n",
    "| Entrenamiento con 600 | (+)    | (+)  | (++)  | (++)    |\n",
    "| Clasificación con modelo entr. con 300 (10^6 ejemplos) | (+)    | (+)  | (++)  | (++)    |\n",
    "| Clasificación con modelo entr. con 600 (10^6 ejemplos) | (+)    | (+)  | (++)  | (++)    |\n",
    "\n",
    "(+) Recuperar datos de la práctica anterior\n",
    "\n",
    "(++) Rellenar estos datos ejecutando el código de arriba\n",
    "</div>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Usando la tabla comenta los resultados.<br/>\n",
    "\n",
    "<ul>\n",
    "<li>(7) ¿Cómo varían los tiempos de entrenamiento al doblar el número de datos de entrenamiento? ¿Y los tiempos de clasificación?</li>\n",
    "<li>(8): Explica los resultados y comparalos con los de un solo árbol</li>\n",
    "</ul>\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\">Respuesta:\n",
    "\n",
    "<ul>\n",
    "<li>(7): </li>\n",
    "<li>(8): </li>\n",
    "</ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Comparativa\n",
    "Vamos a comparar los resultados de clasificación de algunos conjuntos de clasificadores y árboles de decisión.\n",
    "\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">Completa el código de abajo para comparar un árbol de decisión y los conjuntos bagging, adaboost y random forest. Se debe obtener el acierto para los conjuntos de datos: pimaND, spamND, magic04 y sonar. Esto se hará usando validación cruzada de 10 hojas.<br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Lista con los ficheros de datos\n",
    "dataset_names = ['pimaND.csv', 'spamND.csv', 'sonar.csv', 'magic04.csv']\n",
    "# Cargo un conjunto de datos\n",
    "idata=1\n",
    "d = pd.read_csv(dataset_names[idata], sep=',')\n",
    "print(dataset_names[idata])\n",
    "\n",
    "# Creamos las particiones en entrenamiento y test para probar los distintos modelos\n",
    "# Es importente que la partición sea igual para todos los modelos de forma que los \n",
    "# errores sean comparables. Eso se puede lograr fijando el random_state\n",
    "indexFolds = KFold(n_splits=10, shuffle=True, random_state=11)\n",
    "\n",
    "# Para conjuntos grades (pe. magic) puede que hacer entrenamiento con el 90% de los datos (como\n",
    "#   sucede con KFold usando n_folds=10) sea inviable. Si tarde damasiado puedes usar la siguiente línea\n",
    "#   para magic y tal vez para spamND\n",
    "#indexFolds = cross_validation.ShuffleSplit(*** RELLENAR AQUI EL TAMAÑO DEL CONJUNTO ***, n_iter=10, test_size=0.8, random_state=0)\n",
    "\n",
    "# Lista con los modelos a probar\n",
    "n_trees = 250\n",
    "modelos = [DecisionTreeClassifier(),\n",
    "          RandomForestClassifier(n_estimators=n_trees),\n",
    "          AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(min_samples_leaf=10), \n",
    "                             n_estimators=n_trees),\n",
    "          BaggingClassifier(n_estimators=n_trees)]\n",
    "names= ['DecisionTree', 'RandomForest', 'AdaBoost    ', 'Bagging     ']\n",
    "\n",
    "# Bucle para recorrer cada modelo a probar\n",
    "for n,clf in zip(names, modelos):\n",
    "    errors = []\n",
    "    # Recorremos las particiones\n",
    "    for idxTr, idxTs in indexFolds.split(d):\n",
    "        # Train model\n",
    "        clf.fit(d.values[idxTr,:-1],d.values[idxTr,-1])\n",
    "        # Validate model\n",
    "        score = clf.score(d.values[idxTs,:-1],d.values[idxTs,-1])\n",
    "        errors.append(1.0 - score)\n",
    "\n",
    "    errors = np.array(errors)\n",
    "    print(\"{}: {:0.3g}%%\".format(n,100*errors.mean()) + \" +- {:.3g}\".format(100*errors.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\"> Resultados:\n",
    "\n",
    "|  Error de test (%) $\\pm$ desv      | Árbol  | RandomForest  | AdaBoost | Bagging |\n",
    "|-----------------------|--------|------|-------|---------|\n",
    "| Pima  | (+)    | (+)  | (+)  | (+)    |\n",
    "| Spam  | (+)    | (+)  | (+)  | (+)    |\n",
    "| Sonar | (+)    | (+)  | (+)  | (+)    |\n",
    "| Magic | (+)    | (+)  | (+)  | (+)    |\n",
    "\n",
    "(+) Rellenar estos datos ejecutando el código implementado. Dar el error y la desviación estándar. Por ejemplo $15.0 \\pm 3.4$\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">\n",
    "Comenta los resultados:\n",
    "\n",
    "</div>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.- Atributos más importantes\n",
    "Vamos a ver cuáles son los atributos más importantes de los conjuntos de datos analizados arriba. Al entrenar el conjunto se guarda en la variable feature\\_importances\\_ la importancia relativa de cada variable medida en función de cómo de alto aparece en cada árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargamos datos\n",
    "fP = 'pimaND.csv'\n",
    "dfP = pd.read_csv(fP, sep=',')\n",
    "lVarsTarg = dfP.columns\n",
    "\n",
    "#\n",
    "#separación training-test\n",
    "X_train, X_test, clases_train, clases_test = train_test_split(dfP.values[:,:-1], dfP.values[:,-1], test_size=0.3, random_state=1)\n",
    "\n",
    "# Lista con los modelos a probar\n",
    "n_trees = 301\n",
    "clf= RandomForestClassifier(n_estimators=n_trees)\n",
    "\n",
    "# Entrenamos\n",
    "clf.fit(X_train,clases_train)\n",
    "\n",
    "# Mostramos los atributos más relevantes\n",
    "_ = plt.bar(np.arange(1,dfP.values.shape[1]), clf.feature_importances_)\n",
    "_ = plt.xticks(np.arange(1,dfP.values.shape[1])+0.5, [lab[0:3] for lab in lVarsTarg[:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div style=\"background-color:#EEEEAA;padding:20px;border:solid;\"> Indica las dos variables más importante para cada conjunto de datos:\n",
    "\n",
    "|  Error de test (%) $\\pm$ desv      | Nombre Variable 1 | Nombre Variable 2 |\n",
    "|-----------------------|--------|------|\n",
    "| Pima  | (+)    | (+)  |\n",
    "| Spam  | (+)    | (+)  |\n",
    "| Sonar | (+)    | (+)  |\n",
    "| Magic | (+)    | (+)  |\n",
    "\n",
    "(+) Rellenar estos datos \n",
    "</div>\n",
    "<br>\n",
    "<div style=\"background-color:#AAEEAA;padding:20px;border:solid;\">\n",
    "Comenta los resultados:\n",
    "\n",
    "</div>\n",
    "<br/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
