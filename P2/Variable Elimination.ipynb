{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afecd9fb",
   "metadata": {},
   "source": [
    "***Javier Sáez Maldonado***\n",
    "\n",
    "***José Antonio Álvarez Ocete***\n",
    "\n",
    "# Métodos Avanzados en Aprendizaje Automático\n",
    "# Algoritmo de eliminación de variables\n",
    "\n",
    "\n",
    "Este algoritmo es utilizado para realizar inferencia en redes. Supongamos que tenemos la factorización de una distribución conjunta \n",
    "\n",
    "$$ P(\\mathbf{X}) = P(X_1, X_2, \\dots, X_N) = \\prod_{i=1}^N P(X_i|Par(X_i))$$ \n",
    "\n",
    "y una evidencia $ \\mathbf{Z}=\\mathbf{z} $, donde $\\mathbf{Z} \\subset \\mathbf{X}$ es un subconjunto de las variables del problema y $\\mathbf{z}$ son sus valores observados. El objetivo es obtener la distribución de parte de las variables del problema, $\\mathbf{W} \\subset \\mathbf{X}$ dada la evidencia $\\mathbf{Z}=\\mathbf{z}$. Es decir queremos obtener $P(\\mathbf{W}|\\mathbf{Z}=\\mathbf{z})$. Para ello debemos:\n",
    "* Reducir los factores que incluyan $\\mathbf{Z}$\n",
    "* Eliminar el resto de variables no incluidas $\\mathbf{W}$\n",
    "\n",
    "$$ P(\\mathbf{W}|\\mathbf{Z}=\\mathbf{z}) = \\sum_{X \\setminus (W\\cup Z)} \\frac{P(\\mathbf{X}\\setminus \\mathbf{Z},\\mathbf{Z}=\\mathbf{z})}{P(\\mathbf{Z}=\\mathbf{z})} \\propto \\sum_{X \\setminus (W\\cup Z)} P(\\mathbf{X}\\setminus \\mathbf{Z},\\mathbf{Z}=\\mathbf{z}) $$\n",
    "\n",
    "\n",
    "Nuestro algoritmo de eliminación de variables para un conjunto de factores $\\mathbf{\\Phi}=\\{\\Phi_1,\\dots,\\Phi_N\\}$ es el siguiente:\n",
    "1.  Reducir todos los factores que contengan alguna variable de $\\mathbf{Z}$ en su dominio, usando la evidencia dada $\\mathbf{Z}=\\mathbf{z}$.\n",
    "2.  Para cada varible X en $\\mathbf{X} \\setminus (\\mathbf{W} \\cup \\mathbf{Z})$, eliminar variable X mediante marginalización:\n",
    "    1. Hacer el producto de todos los factores que tienen X es su dominio: $\\psi = \\prod_{\\Phi_i \\mid X\\in Dom(\\Phi_i) }\\Phi_i$.\n",
    "    2. Marginalizar X del factor producto obtenido en A: $\\tau = \\sum_X \\psi$.\n",
    "    3. Actualizar la lista de factores quitando los factores que incluyen X y añadiendo el factor marginalizado $\\tau$: $\\mathbf{\\Phi} = (\\mathbf{\\Phi} \\setminus {\\psi}) \\cup \\tau$.\n",
    "3. Multiplicar factores restantes.\n",
    "4. Renormalizar para obtener una distribución.\n",
    "\n",
    "## Implementación\n",
    "\n",
    "Explicado teóricamente, pasamos a realizar la implementación del algoritmo. Usaremos la implementación de ciertas funciones que serán de utilidad que han sido proporcionadas por el profesor en los cuadernos de teoría, así como la cabecera de la función proporcionada también en estos cuadernos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a85682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize(distribution):\n",
    "    \"\"\"\n",
    "    This function normalizes a distribution given as a parameter so that it integrates 1\n",
    "    \"\"\"\n",
    "    return distribution/np.sum(distribution)\n",
    "\n",
    "def reduce(distribution, variables, asignments, normalize_output=True):\n",
    "    \"\"\" This function receives a distribution, \n",
    "        a list of indices to variables and \n",
    "        a list of the assignements to those variables \"\"\"\n",
    "    \n",
    "    reduced = distribution.copy()\n",
    "    \n",
    "    for variable, asignment in zip(variables,asignments):\n",
    "        reduced = np.swapaxes(reduced, 0, variable)[[asignment]]\n",
    "        reduced = np.swapaxes(reduced, 0, variable)\n",
    "        \n",
    "    return normalize(reduced) if normalize_output else reduced\n",
    "\n",
    "def marginal(distribution, variables):\n",
    "    \"\"\" Marginalizes the distributions for the given list of variables \"\"\"\n",
    "    \n",
    "    return np.sum(distribution, axis=tuple(variables), keepdims=True)\n",
    "\n",
    "def array_product(arrays):\n",
    "    \"\"\" Element-wise array product\"\"\"\n",
    "    res = arrays[0]\n",
    "    for arr in arrays[1:]:\n",
    "        res = res * arr\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd710fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VA(factor_list, W, Zs=[], zs=[], order=[]):\n",
    "    \"\"\" Implementar variable elimination algorithm\n",
    "    \n",
    "        Entrada:\n",
    "           * factor_list: lista con los factores a procesar\n",
    "           * W:           lista de variables en el factor de salida\n",
    "           * Zs:          lista de variables observadas\n",
    "           * zs:          lista de valores de las variables observadas\n",
    "           * order:       orden en que se procesan las variables. Si no se \n",
    "                          indica nada se hacer en orden ascendente\n",
    "        Salida:\n",
    "           * Factor con la distribucion conjunta W dada la evidencia\n",
    "           * El tamaño del factor más grande que se procese\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Safe copy of the factors\n",
    "    factors = factor_list.copy()\n",
    "    variables_factors = np.arange(len(factors))\n",
    "    \n",
    "    # -------------------------------------\n",
    "    # Step 1: Reduce factors using Z = z\n",
    "    # -------------------------------------\n",
    "    for Z,z in zip(Zs,zs):\n",
    "        for i,factor in enumerate(factors):\n",
    "            # Check if factor has that variable:\n",
    "            if factor.shape[Z] > 1:\n",
    "                factors[i] = reduce(factor,[Z],[z],False)\n",
    "        \n",
    "    # -------------------------------------\n",
    "    # Step 2: Eliminate variables using marginalization\n",
    "    # ------------------------------------- \n",
    "    \n",
    "    # Get variables in X \\ (W U Z), respecting desired order\n",
    "    rest = order if len(order) > 0 else np.setdiff1d(variables_factors, np.union1d(W, Zs))\n",
    "\n",
    "    max_size = 0    \n",
    "    for X in rest:\n",
    "        # Get the index of the factors that have the variable X\n",
    "        idx = [i for i in variables_factors if factors[i].shape[X] > 1]\n",
    "        # Compute psi distribution\n",
    "        psi = array_product([factors[i] for i in idx])\n",
    "        \n",
    "        # Marginalize X from the obtained product\n",
    "        tau = marginal(psi,[X])\n",
    "        \n",
    "        # Update factors list\n",
    "        factors = [factors[i] for i in np.setdiff1d(variables_factors, idx)] + [tau]\n",
    "        variables_factors = np.arange(len(factors))\n",
    "        \n",
    "        # Update max size\n",
    "        max_size = max(max_size,np.prod(psi.shape))\n",
    "        \n",
    "    \n",
    "    return normalize(array_product(factors)),max_size\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1bb60e",
   "metadata": {},
   "source": [
    "# Casos de prueba\n",
    "\n",
    "Basándonos en la siguiente red bayesiana dada como grafo:\n",
    "\n",
    "![Bayesian Network](estu2.png)\n",
    "\n",
    "Vamos a hacer inferencia sobre variables utilizando el algoritmo de eliminación de variables. Las letras del grafo representan las variables:\n",
    "\n",
    "- Nota examen (G): sobresaliente-g0, notable-g1, aprobado-g2\n",
    "- Dificultad examen (D): fácil-d0, difícil-d1\n",
    "- Inteligencia (I): normal-i0, alta-i1\n",
    "- Nota selectividad (S): alta-s1, baja-s0\n",
    "- Carta de recomendación (L): buena-1, regular-l0\n",
    "\n",
    "Usando la regla de la cadena sobre variables, tenemos que la distribución de esta red viene dada por:\n",
    "\n",
    "$$\n",
    "P(D,I,G,L,S) = P(D)P(I|D)P(G|D,I)P(L|D,I,G)P(S|D,I,G,L)\n",
    "$$\n",
    "\n",
    "Ahora, se ha visto también en clase que se pueden eliminar ciertas dependencias entre las variables para simplificar esta distribución, quedando como resultado que la distribución conjunta viene dada por:\n",
    "\n",
    "$$\n",
    "P(D,I,G,L,S) = P(D)P(I)P(G|D,I)P(L|G)P(S|I)\n",
    "$$\n",
    "\n",
    "\n",
    "Lo primero que tenemos que hacer es definir matricialmente usando `NumPy` las distribuciones de probabilidad que nos van a dar cada una de las variables recientemente explicadas. Además, establecemos un orden para las mismas. Definimos además la distribución conjunta como el producto definido en la ecuación anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "204dd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definamos los factores del problema con el siguiente orden de \n",
    "# variables\n",
    "\n",
    "# Dimensión -> 0  1  2  3  4\n",
    "# Variable  -> I, D, G, L, S\n",
    "\n",
    "PI = np.array([0.7, 0.3]).reshape((2,1,1,1,1))\n",
    "PD = np.array([0.6, 0.4]).reshape((1,2,1,1,1))\n",
    "PG_ID = np.array([0.3, 0.4, 0.3, 0.05, 0.25, 0.7, 0.9, 0.08, 0.02, 0.5, 0.3, 0.2]).reshape((2,2,3,1,1))\n",
    "PL_G = np.array([0.1, 0.9, 0.4, 0.6, 0.99, 0.01]).reshape((1,1,3,2,1))\n",
    "PS_I = np.array([0.95, 0.05, 0.2, 0.8]).reshape((2,1,1,1,2))\n",
    "\n",
    "# Distribución conjunta\n",
    "PIDGLS = PI*PD* PG_ID * PL_G* PS_I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc9a6e4",
   "metadata": {},
   "source": [
    "A continuación, vamos a realizar una serie de pruebas para probar que nuestro algoritmo funciona correctamente.\n",
    "\n",
    "Comenzamos calculando las tres siguientes cantidades:\n",
    "\n",
    "- La distribución de la inteligencia $P(I)$\n",
    "- La distribución $P(I|G = g_2)$, es decir, la distribución de la inteligencia condicionada a que la nota del examen ha sido aprobado.\n",
    "- La distribución $P(I|G=g_2,D = d_1)$, es decir, la anterior pero condicionando también a que el examen fue difícil.\n",
    "\n",
    "\n",
    "Conocemos de antemano los valores que deberíamos obtener, así que el código funcionará de la siguiente manera:\n",
    "\n",
    "1. Obtendrá los valores requeridos.\n",
    "2. Terminará la ejecución si estos son incorrectos ó imprimirá por pantalla *All tests work ok* si todo funciona correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9528c327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests work ok.\n"
     ]
    }
   ],
   "source": [
    "# Calcula la distribución P(I)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[0])\n",
    "assert(np.allclose(np.array([[[[[0.7]]]],[[[[0.3]]]]]),factor))\n",
    "assert(maxsize==12)\n",
    "\n",
    "# Si sabemos que la nota del examen es aprobado, ¿Cuál es la prob de inteligencia? \n",
    "# P(I|G=g2)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[0],[2],[2])\n",
    "assert(np.allclose(np.array([[[[[0.92105263]]]],[[[[0.07894737]]]]]), factor))\n",
    "assert(maxsize==4)\n",
    "\n",
    "# y si además el examen es difícil\n",
    "# P(I|G=g2,D=d1)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[0],[1,2],[1,2])\n",
    "assert(np.allclose(np.array([[[[[0.89090909]]]],[[[[0.10909091]]]]]), factor))\n",
    "assert(maxsize==4)\n",
    "\n",
    "print(\"All tests work ok.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceda2a9",
   "metadata": {},
   "source": [
    "Repetimos el proceso atnerior, calculando ahora:\n",
    "\n",
    "- La distribución de probabilidad de la dificultad de un examen $P(D)$.\n",
    "- La distribución $P(D|G = g_2)$, que nos da la distribibución de la dificultad de un examen sabiendo que la nota ha sido aprobado.\n",
    "- La probabilidad $P(D|G = g_2,S = s_1)$, que nos da la probabilidad de que un examen sea difícil sabiendo que se ha aprobado y que la nota de selectividad ha sido alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73cf0f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests work ok.\n"
     ]
    }
   ],
   "source": [
    "# Prob examen: Calcula la distribución: P(D)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[1])\n",
    "assert(np.allclose(np.array([[[[[0.6]]],[[[0.4]]]]]),factor))\n",
    "assert(maxsize==24)\n",
    "\n",
    "# Prob examen | nota aprobado: P(D|G=g2)\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2],[2])\n",
    "assert(np.allclose(np.array([[[[[0.37070938]]],[[[0.62929062]]]]]),factor))\n",
    "assert(maxsize==8)\n",
    "\n",
    "# Probabilidad de examen difícil D=d1|G=g2,S=s1?\n",
    "factor, maxsize = VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2,4],[2,1])\n",
    "assert(np.allclose(np.array([[[[[0.24044002]]],[[[0.75955998]]]]]),factor))\n",
    "assert(maxsize==4)\n",
    "\n",
    "print(\"All tests work ok.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1dce2",
   "metadata": {},
   "source": [
    "Por último, asumiremos que no se conoce $G$, y queremos comprobar si la nota de selectividad influye en la nota del examen. Realizamos el siguiente proceso:\n",
    "\n",
    "1. Imprimir la distribución de la dificultad $P(D)$.\n",
    "2. Imprimir la dificultad del examen si la nota de selectividad es alta $P(D|S=s_1)$\n",
    "3. Imprimir la dificultad del examen si la nota es aprobado $P(D|G = g_2)$\n",
    "4. Imprimir la distribución condicionada a los dos casos anteriores $P(D|S = s_1,G = g_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f4bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de la dificultad\n",
      "[[[[[0.6]]]\n",
      "\n",
      "\n",
      "  [[[0.4]]]]]\n",
      "\n",
      "Dificultad del examen si la nota de selectividad es alta\n",
      "[[[[[0.6]]]\n",
      "\n",
      "\n",
      "  [[[0.4]]]]]\n",
      "No hay cambio\n",
      "\n",
      "Dificultad del examen si la nota es aprobado\n",
      "[[[[[0.37070938]]]\n",
      "\n",
      "\n",
      "  [[[0.62929062]]]]]\n",
      "Cambia\n",
      "\n",
      "Dificultad del examen si la nota de selectividad es alta y  la nota es aprobado\n",
      "[[[[[0.24044002]]]\n",
      "\n",
      "\n",
      "  [[[0.75955998]]]]]\n",
      "Cambia\n"
     ]
    }
   ],
   "source": [
    "def print_change(D1,D2):\n",
    "    if np.allclose(D1,D2):\n",
    "        print(\"No hay cambio\")\n",
    "    else:\n",
    "        print(\"Cambia\")\n",
    "\n",
    "\n",
    "# Si no se conoce G, ¿Influye la nota de selectividad en la dificultad del examen?\n",
    "# dif examen\n",
    "print(\"Distribución de la dificultad\")\n",
    "D,_ = VA([PI, PD, PG_ID, PL_G, PS_I],[1])\n",
    "print(D)\n",
    "\n",
    "\n",
    "# dif examen si sat=1\n",
    "print(\"\\nDificultad del examen si la nota de selectividad es alta\")\n",
    "D_S1, _ = VA([PI, PD, PG_ID, PL_G, PS_I],[1],[4],[1])\n",
    "print(D_S1) # No cambia\n",
    "\n",
    "print_change(D,D_S1)\n",
    "\n",
    "# Ahora sabiendo que nota es aprobado\n",
    "print(\"\\nDificultad del examen si la nota es aprobado\")\n",
    "D_G2 , _ =VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2],[2])\n",
    "print(D_G2)\n",
    "print_change(D_G2,D)\n",
    "\n",
    "# Ahora sabiendo ambas cosas\n",
    "print(\"\\nDificultad del examen si la nota de selectividad es alta y  la nota es aprobado\")\n",
    "D_S1_G2, _ = VA([PI, PD, PG_ID, PL_G, PS_I],[1],[2,4],[2,1])\n",
    "print(D_S1_G2)# Sí cambia\n",
    "print_change(D,D_S1_G2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535b6aa",
   "metadata": {},
   "source": [
    "Podemos ver que únicamente la nota de selectividad no afecta a la dificultad, pero si la nota del examen es aprobado sí que afecta a la distribución de la dificultad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
